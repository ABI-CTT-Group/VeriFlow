Project Title: VeriFlow (The Verifiable Workflow Architect)
Elevator Pitch
VeriFlow is an autonomous "Research Reliability Engineer" designed primarily to ensure Scientific Reproducibility. It solves the crisis of non-replicable science by using Gemini 3 to ingest scientific publications, extract their methodological logic, and verify their code repositories. It automatically packages these components into verifiable, executable "Lego blocks" (Docker containers described in CWL) and assembles them into a standardized, FAIR-compliant workflow. By leveraging the SPARC Dataset Structure (SDS) as its internal currency and the ISA Framework for experimental context, VeriFlow ensures that every measurement, tool, model, and study design is interoperable. For the hackathon, VeriFlow focuses on Autonomous Replication: allowing researchers to chat with the system to visualize and instantiate a verified workflow from a PDF and execute it on the paper's original data. Future phases will extend this to dynamically add new capabilities (e.g., calculating the volume of a tumor from the segmentation masks generated by the replicated workflow) and run workflows on user-provided datasets.
1. Data Object Standardization Strategy
To ensure VeriFlow is future-proof and interoperable, we strictly separate the Methodology (how agents reason) from the Serialization Rules (how data is stored). This allows us to swap standards (e.g., moving to RO-Crates in the future) without retraining the agents.
The "Universal Adapter" Infrastructure
 * Core Standard (Hackathon): We utilize the SPARC Dataset Structure (SDS) (https://docs.sparc.science/docs/sparc-dataset-structure) as the fundamental format for all internal data objects.
 * Internal Description Standard: We use Common Workflow Language (CWL) as the internal description format for all Tool and Workflow Data Objects. This maximizes interoperability, allowing the same workflow definition to be run by different execution engines.
 * Execution Engine (Hackathon): For the purposes of this hackathon, we utilize Apache Airflow 3 as the execution engine. We leverage its API to execute and monitor workflow execution in VeriFlow. Any necessary conversion from the internal CWL description to the Airflow execution format is performed dynamically at runtime.
 * ISA Framework Integration: We leverage the ISA (Investigation, Study, Assay) framework to extract and serialize the experimental context from papers.
 * Serialization Tooling: We employ sparc-me (https://github.com/SPARC-FAIR-Codeathon/sparc-me) to programmatically generate these datasets.
 * Adapter Pattern: The infrastructure is designed with adapters. While SDS is the internal standard for metadata and organization, "Input Adapters" convert these SDS objects into the specific file formats required by individual computational tools. VeriFlow dynamically adds adapter tools as needed to help match Measurement Samples and inputs to Tools (e.g., resampling, file conversion). If a match is not feasible or appropriate, the system will propose an alternative approach. In the future, "Output Adapters" could serialize the same objects into RO-Crates or BIDS.
 * VeriFlow API: The tool exposes a comprehensive REST/gRPC API, enabling programmatic access to all functions—from parsing PDFs and generating SDS objects to executing workflows and querying the Knowledge Base—allowing external scripts to drive the entire replication lifecycle.
Data Object Rules (The "SDS Blueprints")
 * Separation of Concerns: We enforce strict separation of data objects. Tools, Models, Investigations, Studies, and Assays are NOT bundled inside measurement datasets. Instead, specific SDS datasets are created for each entity type. This ensures they remain modular, reusable objects independent of the specific data they process.
 * ISA Hierarchy Serialization:
   * Investigation, Study, and Assay objects are extracted and serialized as separate SDS datasets.
   * Their descriptions are stored in the primary folder of their respective datasets.
   * Unlike measurement datasets, these ISA datasets do not contain subjects or samples.
   * Linking: Metadata must explicitly link these objects together (Assay \rightarrow Study \rightarrow Investigation). Each Assay will have one Workflow associated with it and link to the specific set of Measurements (samples) it processes, which may come from one or more external Measurement SDS datasets.
 * Models vs. Tools:
   * Models (e.g., pre-trained weights for nnU-Net) are distinguished from Tools (the executable software, e.g., the nnU-Net code).
   * Models are serialized in their own dedicated Model SDS.
   * A model dataset is similar to a measurement dataset except that it doesn’t have subjects or samples, with the model being stored in the primary folder.
   * Linking: The Model SDS metadata must explicitly link to the Tool SDS that it is associated with.
 * Derived Data & Provenance:
   * When a tool generates new data (e.g., a tumor segmentation mask), this derived data is placed in the primary folder of a newly created Measurement SDS.
   * Provenance: The metadata of this new dataset must explicitly link back to:
     * The Original Source SDS (e.g., the MRI data) via wasDerivedFrom.
     * The specific Tool SDS and Workflow SDS used to generate it, ensuring full reproducibility.
 * Workflow Inputs & Outputs:
   * A Workflow is defined by Inputs and Outputs that map to the underlying tools.
   * Execution Logic: Running the workflow involves running each tool for each subject in the measurement dataset.
   * Intermediate Data: By default, only the final Workflow Outputs are saved as persistent SDS samples. Intermediate outputs (passed between internal tools) are transient. However, the system provides a user option to "Save Intermediate Results," which forces the serialization of these transient steps into SDS datasets.
   * Routing: Workflow outputs can be routed to the same SDS if appropriate, but the user can specify if specific samples (e.g., a critical biomarker) should be routed to a different, dedicated SDS.
 * Workflows as Objects: The orchestration logic (CWL) is itself stored as a distinct Data Object within its own SDS. This CWL definition acts as the "source of truth" to maximize interoperability. When execution is required, this CWL object is converted (if necessary) to the format required by the execution engine (e.g., Airflow 3).
 * Metadata Enrichment & Type Mapping:
   * All objects must be populated with rich metadata tags (using the SPARC ontology) to enable automated execution.
   * MIME-Types & File Formats: To enable automated tool assembly and input/output matching, we mandate the use of the additional_type field in the SDS manifest files.
   * Implementation: Each file added to an SDS must include a specific MIME-type or standard file format identifier (e.g., edam:format_3987 for NIfTI) in its additional_type metadata. This field can also include software version numbers if needed.
   * Usage: These descriptors are used by the Engineer Agent to strictly enforce compatibility between tool requirements (e.g., "Input requires application/x-nifti") and available measurement data, ensuring that workflows are assembled with type safety.
 * Incremental Population: The SDS datasets are populated throughout the stages. For example, during the Workflow Description Templating stage, the assay files and their metadata are added to the Assay SDS, while only the measurement metadata is added to the Measurement SDS (as the data would only be accessed during the Workflow Execution and Diagnostics stage).
 * Exportability: At each stage of VeriFlow, it is expected that the user can download the SDS datasets.
2. Methodology: The "Triad of Trust"
VeriFlow replaces generic AI agents with three specialized roles powered by Gemini 3. These agents follow the standardization rules defined above to ensure consistency across the four defined stages: Workflow Description Templating, Workflow Execution Templating, Workflow Execution and Diagnostics, and Workflow Results Review.
Agent A: The Scholar (Literature & Metadata)
 * Role: Extracts the "Theory" and populates Data Objects.
 * Tech: Gemini 3 (Multimodal & Long Context).
 * Stage: Primarily active during Workflow Description Templating.
 * Task:
   * Ingestion: Scans the PDF text, equations, and system diagrams to understand the sequence of operations.
   * ISA & Object Creation: Responsible for creating the distinct SDS datasets. It utilizes sparc-me logic to define separate datasets for:
     * Investigation, Study, Assay (Context).
     * Measurements (Subject/Sample raw data).
     * Tools (Executable code).
     * Models (Pre-trained weights).
   * Metadata Population: Extracts entities (e.g., "T1-weighted MRI", "nnU-Net Weights") and populates the SDS metadata fields according to the "SDS Blueprints," ensuring the Assay links to the correct Workflow and Measurements, and the Model links to the correct Tool. Crucially, it populates Tool and Workflow objects in CWL format to serve as the internal description standard.
Agent B: The Engineer (Code & Infrastructure)
 * Role: Handles the "Reality" (messy code).
 * Tech: Gemini 3 (Code Optimization).
 * Stage: Active during Workflow Execution Templating and Workflow Execution and Diagnostics.
 * Task:
   * Dependency Forensics: Scans GitHub repositories. If requirements.txt is missing, it infers libraries and versions based on code timestamps and import statements.
   * Containerization: Generates a verifiable Dockerfile and wraps it in CWL. These CWL definitions are stored in their own dedicated Workflow SDS.
   * Execution Conversion: At runtime, it performs any necessary conversion of the CWL workflow definition to the execution engine's format (e.g., generating Airflow 3 DAGs from the CWL source).
   * Adapter Generation: Writes the specific "glue code" needed to feed data from a Measurement SDS and weights from a Model SDS into the containerized tool. It dynamically adds adapter tools (e.g., image re-slicing, format conversion) to the workflow to ensure measurement samples match tool inputs. It leverages the additional_type (MIME-type) metadata to identify mismatches (e.g., connecting a DICOM output to a NIfTI input) and injects the appropriate converters.
   * Self-Healing: If a match is not feasible, it flags the incompatibility to the Reviewer Agent to propose an alternative.
Agent C: The Reviewer (Validation, Support & Interface)
 * Role: The "Senior Developer" Interface & Full-Cycle Support.
 * Tech: Gemini 3 (Deep Think).
 * Stage: Active throughout, with focus on Workflow Results Review.
 * Task:
   * Services Integration: VeriFlow and its agents can leverage two services:
     * a. Catalogue: A list of all the different data objects that have been extracted from the paper.
     * b. Dataset Viewer: A service where the user can:
       * i. Directly (or conversationally through the reviewer agent) dynamically edit metadata of each dataset.
       * ii. Navigate and view files using embedded viewers e.g., view mesh or segmentation using VolView.
   * Proactive Data Validation (Creation Phase): Acts as a gatekeeper, validating that the benchmark data retrieved from the paper matches the generated SDS schemas before execution begins. For example, it checks the additional_type metadata to ensure the downloaded sample data is in the correct 3D NIfTI format required by the tool.
   * Runtime Diagnostics (Execution Phase): Monitors the workflow live via the Airflow 3 API. If a tool crashes during replication, the Reviewer Agent doesn't just show an error code; it translates the technical Docker/Airflow logs into actionable scientific advice.
   * Scientific "Unit Tests" (Diagnosis Phase): Validates input/output compatibility by checking the SDS metadata. For example, it confirms that a Sample tagged with unit: voxel is not fed into a Tool expecting unit: mm3.
3. Case Studies (Applied Examples)
To demonstrate VeriFlow's versatility, we apply the methodology above to two distinct datasets and workflows. For the current hackathon phase, the focus is on Replicating the results using the data provided by the papers.
Example A: Breast Cancer Segmentation (The "MAMA-MIA" Workflow)
 * Source: A large-scale multicenter breast cancer DCE-MRI benchmark dataset.
 * The Goal (Replication): Replicate the automated tumor segmentation described in the paper using the paper's own benchmark dataset.
 * VeriFlow Execution:
   * Stage 1: Workflow Description Templating: Scholar Agent ingests the PDF. Identifies the Investigation (Breast Cancer Benchmark) and Study (Multicenter validation). It creates an Assay SDS for the segmentation task. It creates an Input Measurement SDS for the MRI scans (populating only metadata). It distinguishes the nnU-Net code (Tool SDS) from the paper's provided pre-trained weights (Model SDS), describing both in CWL format.
   * Stage 2: Workflow Execution Templating: Reviewer Agent checks the downloaded benchmark data. Engineer Agent clones the repo and builds the container. It dynamically adds a NIfTI-to-NIfTI resampling adapter to match the input resolution. It configures the output logic so that the resulting segmentation mask is stored as defined by the SDS Blueprints. It ensures the Tool container correctly mounts the weights from the Model SDS.
   * Stage 3: Workflow Execution and Diagnostics: It converts the final CWL definition into an Airflow 3 DAG. The system runs the workflow, iterating each tool for each subject in the measurement dataset. Reviewer Agent monitors execution.
   * Stage 4: Workflow Results Review: Reviewer Agent validates the final output. It ensures the New Derived SDS metadata contains provenance links (wasDerivedFrom) pointing to the Input SDS and the specific nnU-Net Tool/Workflow used.
Example B: Cardiac Digital Twin (The "biv-me" Workflow)
 * Source: An Open-Source End-to-End Pipeline for Generating 3D+t Biventricular Meshes.
 * The Goal (Replication): Create a digital twin of a heart (biventricular mesh) from the raw CMR images provided in the paper's sample repository.
 * VeriFlow Execution:
   * Stage 1: Workflow Description Templating: Scholar Agent maps the pipeline (View Classification \rightarrow Segmentation \rightarrow Contours \rightarrow Model Fitting). It creates separate SDS datasets for the Investigation/Study context. It creates Tool SDSs for the pipeline code and Model SDSs for the pre-trained ResNet and U-Net weights used in the classification and segmentation steps. It creates an Input Measurement SDS for the raw CMR images (metadata only).
   * Stage 2: Workflow Execution Templating: Engineer Agent scans the repo. It generates a "Data Validator" adapter. It ensures that the final biventricular mesh is stored as defined by the SDS Blueprints, linking the execution back to the specific Assay and Study.
   * Stage 3: Workflow Execution and Diagnostics: During the run (orchestrated by Airflow 3 and iterating through all subjects), the "Model Fitting" step fails on one of the sample subjects. The Reviewer Agent analyzes the logs: "The solver failed to converge for Subject 004."
   * Stage 4: Workflow Results Review: Once successful, the Reviewer Agent checks the temporal coherence of the output mesh.
4. User Interface & Experience Strategy
The user interface for VeriFlow is designed to be minimalistic, modular, and highly flexible. The layout is structured into collapsible, resizable panels that persist state across operations. When designing the UI/UX, only the hackathon examples (Breast Cancer Segmentation and Cardiac Digital Twin) should be used.
General UI Requirements:
 * Collapsible & Adjustable: All modules are collapsible and resizable, with the exception of the central Workflow Assembler which remains visible.
 * Drag-and-Drop: Supported for file uploads and visual workflow assembly.
 * State Persistence: UI state (e.g., expanded panels, PDF URL) persists across operations.
 * Visual Design: Uses a specific color system—Blue for Measurement Nodes, Purple for Tool Nodes, and Green for Model Nodes.
Module Definitions & Layout:
 * Upload Publication Module (Left Panel - Top):
   * Function: Drag-and-drop file upload for PDFs, ZIPs, and code repositories.
   * Behavior: Default state is expanded; automatically collapses after a successful upload to reveal the Study Design.
 * Review Study Design Module (Left Panel - Bottom):
   * Function: Displays a tree structure of the extracted research study (Study \rightarrow Subjects/Assays) with confidence scores.
   * Interaction: Clicking a source citation opens the Viewer Panel. Selecting an assay enables the "Assemble Workflow" action, which collapses the left panel and populates the center canvas.
 * Workflow Assembler Module (Center Panel):
   * Workflow Canvas (Top): A node-based visual graph editor.
     * Measurement Nodes (Blue): Containers for dataset collections.
     * Tool Nodes (Purple): Processing steps with input/output ports.
     * Model Nodes (Green): Configuration parameters.
     * Interaction: Nodes are connected via drag-and-drop logic (Output port \rightarrow Input port).
   * Data Object Catalogue (Middle Left): A tree view of all discovered data objects (Inputs/Outputs), separated by collapsible sections. Objects can be dragged onto the canvas.
   * Viewer Panel (Middle Right): Displays PDF citations and documentation. Includes a plugin system (Auto, PDF.js, Embed) and auto-expands when a source button is clicked.
 * Visualise and Export Results Module (Right Panel):
   * Function: A file tree viewer for exploring the SDS directory structure (e.g., primary/, derivative/, code/).
   * Behavior: Auto-expands when the workflow runs. Selecting a workflow node filters the file tree to show relevant datasets.
 * Console Module (Bottom Panel):
   * Function: Real-time logging of workflow execution, status messages, and error reporting.
   * Behavior: Resizable via the top border. Logs categories include system initialization, assembly events, and execution progress.
5. Technical Architecture
The system uses the Model Context Protocol (MCP) to decouple Gemini 3's reasoning from the underlying infrastructure. Ideally, the VeriFlow interface is built using Vue 3 (or React as per implementation details).
 * The Brain (Gemini 3): Orchestrates the process. Maintains the state of the "Assembly Line."
 * MCP Server: scholar-tools (Literature parsing, sparc-me execution, SPARC ontology lookup, CWL object generation).
 * MCP Server: devops-tools (Docker build, CWL generation, GitHub cloning, Adapter creation, CWL-to-Airflow conversion).
 * MCP Server: reviewer-tools (Dynamic visualisation, Catalogue management, Input validation, Log analysis via Airflow API, Workflow critique, Reliability scoring, VolView integration).
6. Hackathon Phases (Development Roadmap)
The development during the hackathon is separated into three distinct phases which map to the VeriFlow stages and utilize the modules described above.
Phase 1: Stage 1 - Workflow Description Templating
 * Focus: The Scholar Agent analyzes the paper to extract the study design (in ISA), workflows (in CWL), tools (in CWL), measurements, and models, creating an SDS with metadata for them all.
 * Action: The focus is on identifying the investigation, study, and assays in the paper using the Review Study Design Module. The system allows the user to select which study and assays they want to replicate. This helps pin down the specific measurements and tools used.
 * Subject Limiting: Some of the studies described in the paper might use a large number of subjects. During the generation of workflow description, the system allows the user to modify the number of subjects to be considered when the workflow is executed. Editing the number of subjects could be either via chat or by updating the subjects field of the measurements SDS.
 * SDS Population: At this stage, the assay files and their metadata are added to the Assay SDS, while only the measurement metadata is added to the Measurement SDS.
 * Support: The Reviewer Agent helps with verifying the extraction and supporting the user. The user can download the SDS datasets generated at this stage.
Phase 2: Stage 2 & 3 - Workflow Execution Templating & Diagnostics
 * Stage 2 (Execution Templating): The Engineer Agent creates containers for tools based on the Scholar’s CWL descriptions, sorts out dependencies, and dynamically adds adapters to map inputs between tools. The user interacts with the Workflow Assembler Module to fine-tune inputs and outputs.
 * Stage 3 (Execution and Diagnostics): It handles the execution of the workflow with Airflow. Running the workflow involves running each tool for each subject in the measurement dataset.
 * Support: The Reviewer Agent helps review the Engineer's blueprint before running. During running, it flags errors and proposes alternatives (including red teaming and Runtime Diagnostics displayed in the Console Module). The user can download the updated SDS datasets (including intermediate results if selected).
Phase 3: Stage 4 - Workflow Results Review
 * Focus: The Reviewer Agent helps compare outputs in the paper with outputs generated by the executed workflow.
 * Extension: One thing that might be needed is to add a new tool (e.g., DICE overlap) if the paper/github doesn’t provide that (this relates to the "extension scenario" future item).
 * Visualisation: For visualisation of results, for now, we simplify things to let the user navigate to the measurement dataset generated by the executed workflow using the Visualise and Export Results Module (Right Panel) and use the built-in viewers (e.g., VolView) to view the results. The user can download the final SDS datasets containing the replication results.
7. Future Roadmap: The "Robustness Trajectory"
This section outlines how VeriFlow evolves from the current replication-focused MVP (Phases 1-3) to a fully generalizable scientific platform.
Phase 4: The "Extension" Scenario (Dynamic Tool Creation & Visualization)
 * Condition: The workflow has been replicated, but the user wants to extend it with functionality not present in the original paper (e.g., calculating tumor volume from the generated segmentation mask) or visually inspect results using specialized tools not described in the paper.
 * Method:
   * Analysis Extensions: VeriFlow dynamically searches its library for an existing tool (e.g., a NIfTI volume calculator) or uses Gemini 3 to generate one. It wraps this tool in a Tool SDS (described in CWL), creates the necessary adapters, and appends it to the workflow.
   * Interactive Visualization Plugins: We incorporate interactive visualization tools into the workflow assembly by leveraging sparc-plugins (https://github.com/SPARC-FAIR-Codeathon/2025-team-D). These tools are added to a pre-populated catalogue and can be dynamically assembled and inserted into the VeriFlow GUI. These plugin tools use the same underlying SDS infrastructure, allowing users to view results seamlessly.
Phase 5: The "User Data" Scenario (External Validation)
 * Condition: The workflow has been verified and replicated. The user now wishes to apply this verified workflow to their own, private datasets.
 * Method: The Reviewer Agent's role expands to external data intake. It uses the SDS schema generated in Phase 1 as a "validator contract." When a user uploads new files, the agent checks them against the schema (e.g., ensuring correct dimensionality and file type) and triggers the workflow only upon successful validation.
Phase 6: The "Partial Knowledge" Scenario (RAG Augmentation)
 * Condition: The paper mentions a standard method (e.g., "We used a ResNet50 for view classification") but provides no code.
 * Method: VeriFlow queries its Knowledge Base. It retrieves a "Verified Block" of a ResNet50 implementation (stored as a separate Tool SDS) from a different paper and links it to the current workflow.
Phase 7: The "Inference" Scenario (DSPy & Synthetic Descriptions)
 * Condition: The paper is vague (e.g., "Data was preprocessed to normalize intensity" with no further detail) and no standard tool exists in the library.
 * Method: We utilize DSPy (Declarative Self-Improving Language Models) to bridge the gap.
   * Synthesize Logic: We use DSPy to optimize a prompt that attempts to write the missing preprocessing code based on the context of the paper's results.
   * Generate Description: DSPy iterates to create a precise, formal description of this missing step that fits the SDS tool schema (in CWL).
   * Template Injection: This synthetic description is fed into the template engine as if it were extracted from the text, effectively allowing the system to "write the missing paragraphs" of the paper to ensure the workflow remains unbroken.
Phase 8: The "Grey Literature" Scenario (Broad Ingestion)
 * Condition: The source information is not a formal paper but "grey literature" like posters, abstracts, or standalone repositories lacking proper documentation.
 * Method: VeriFlow adapts its Scholar Agent to handle unstructured and partial inputs. It utilizes its established Knowledge Base to infer missing context (e.g., inferring the methodology of an abstract by finding similar full papers) and ingests standalone repositories by performing deep code analysis to auto-generate the missing methodological descriptions. This extends VeriFlow's reach to the "cutting edge" of pre-print and pre-publication science.