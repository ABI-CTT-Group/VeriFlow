{
  "inputs": {
    "isa_summary": "ISA JSON present",
    "repo_path": "/app/examples/data/70611af3-3aa6-4c47-b361-2881ec2fea0f"
  },
  "prompt_truncated": "You are a Principal DevOps Engineer. \nMap the Theoretical ISA Design to EXECUTABLE, SELF-CONTAINED CWL Code.\n\nCRITICAL REQUIREMENTS:\n1. **Self-Contained Scripts**: You MUST use `InitialWorkDirRequirem...",
  "model_thoughts": [],
  "final_output": {
    "Dockerfile": "FROM python:3.9-slim\n\n# Install system dependencies\nRUN apt-get update && apt-get install -y --no-install-recommends \\\n    build-essential \\\n    && rm -rf /var/lib/apt/lists/*\n\n# Install Python packages required for the pipeline\nRUN pip install --no-cache-dir \\\n    dicom2nifti \\\n    nibabel \\\n    numpy \\\n    pandas \\\n    argparse\n\n# Set working directory\nWORKDIR /app\n",
    "tool1_dicom_convert.cwl": "#!/usr/bin/env cwl-runner\ncwlVersion: v1.2\nclass: CommandLineTool\n\nlabel: DICOM to NIfTI Converter\ndoc: Converts a directory of DICOM images to a single NIfTI file.\n\nbaseCommand: [\"python\", \"convert_dicom.py\"]\n\nrequirements:\n  DockerRequirement:\n    dockerPull: python:3.9-slim\n  InitialWorkDirRequirement:\n    listing:\n      - entryname: convert_dicom.py\n        entry: |\n          import os\n          import dicom2nifti\n          import argparse\n          import sys\n\n          def run_conversion(input_dir, output_file):\n              print(f\"Converting {input_dir} to {output_file}\")\n              try:\n                  dicom2nifti.dicom_series_to_nifti(input_dir, output_file, reorient_nifti=True)\n              except Exception as e:\n                  print(f\"Error converting dicom: {e}\")\n                  sys.exit(1)\n\n          if __name__ == \"__main__\":\n              parser = argparse.ArgumentParser()\n              parser.add_argument(\"--input_dir\", required=True)\n              parser.add_argument(\"--output_file\", required=True)\n              args = parser.parse_args()\n              run_conversion(args.input_dir, args.output_file)\n\ninputs:\n  dicom_directory:\n    type: Directory\n    inputBinding:\n      prefix: --input_dir\n\noutputs:\n  nifti_image:\n    type: File\n    outputBinding:\n      glob: \"output.nii.gz\"\n    doc: The converted NIfTI file\n\narguments:\n  - prefix: --output_file\n    valueFrom: \"output.nii.gz\"\n",
    "tool2_standardize.cwl": "#!/usr/bin/env cwl-runner\ncwlVersion: v1.2\nclass: CommandLineTool\n\nlabel: Image Standardization\ndoc: Standardizes image orientation to canonical (RAS/LAS).\n\nbaseCommand: [\"python\", \"standardize.py\"]\n\nrequirements:\n  DockerRequirement:\n    dockerPull: python:3.9-slim\n  InitialWorkDirRequirement:\n    listing:\n      - entryname: standardize.py\n        entry: |\n          import nibabel as nib\n          import argparse\n          import os\n\n          def standardize(input_path, output_path):\n              print(f\"Standardizing {input_path}...\")\n              img = nib.load(input_path)\n              # Convert to closest canonical orientation\n              new_img = nib.as_closest_canonical(img)\n              nib.save(new_img, output_path)\n              print(f\"Saved to {output_path}\")\n\n          if __name__ == \"__main__\":\n              parser = argparse.ArgumentParser()\n              parser.add_argument(\"--input_file\", required=True)\n              parser.add_argument(\"--output_file\", required=True)\n              args = parser.parse_args()\n              standardize(args.input_file, args.output_file)\n\ninputs:\n  nifti_image:\n    type: File\n    inputBinding:\n      prefix: --input_file\n\noutputs:\n  harmonized_nifti:\n    type: File\n    outputBinding:\n      glob: \"harmonized.nii.gz\"\n\narguments:\n  - prefix: --output_file\n    valueFrom: \"harmonized.nii.gz\"\n",
    "tool3_segmentation.cwl": "#!/usr/bin/env cwl-runner\ncwlVersion: v1.2\nclass: CommandLineTool\n\nlabel: Automated Segmentation (Mock nnU-Net)\ndoc: Simulates a deep learning segmentation model (produces a threshold-based mask).\n\nbaseCommand: [\"python\", \"segment.py\"]\n\nrequirements:\n  DockerRequirement:\n    dockerPull: python:3.9-slim\n  InitialWorkDirRequirement:\n    listing:\n      - entryname: segment.py\n        entry: |\n          import nibabel as nib\n          import numpy as np\n          import argparse\n\n          def segment(input_path, output_path):\n              print(f\"Running inference on {input_path}...\")\n              img = nib.load(input_path)\n              data = img.get_fdata()\n              \n              # Mock segmentation: simple thresholding to create a binary mask\n              # In a real scenario, this would load weights and run a DL model\n              threshold = np.mean(data)\n              mask = (data > threshold).astype(np.uint8)\n              \n              seg_img = nib.Nifti1Image(mask, img.affine, img.header)\n              nib.save(seg_img, output_path)\n              print(f\"Segmentation saved to {output_path}\")\n\n          if __name__ == \"__main__\":\n              parser = argparse.ArgumentParser()\n              parser.add_argument(\"--input_file\", required=True)\n              parser.add_argument(\"--output_file\", required=True)\n              args = parser.parse_args()\n              segment(args.input_file, args.output_file)\n\ninputs:\n  harmonized_nifti:\n    type: File\n    inputBinding:\n      prefix: --input_file\n\noutputs:\n  preliminary_segmentation:\n    type: File\n    outputBinding:\n      glob: \"segmentation.nii.gz\"\n\narguments:\n  - prefix: --output_file\n    valueFrom: \"segmentation.nii.gz\"\n",
    "tool4_manual_correction.cwl": "#!/usr/bin/env cwl-runner\ncwlVersion: v1.2\nclass: CommandLineTool\n\nlabel: Manual Correction Simulator\ndoc: Simulates the expert manual correction step by passing through the segmentation (or modifying it).\n\nbaseCommand: [\"python\", \"manual_correct.py\"]\n\nrequirements:\n  DockerRequirement:\n    dockerPull: python:3.9-slim\n  InitialWorkDirRequirement:\n    listing:\n      - entryname: manual_correct.py\n        entry: |\n          import shutil\n          import argparse\n          import os\n\n          def correct(seg_input, img_input, output_path):\n              # In a real workflow, this might invoke a viewer or wait for human input.\n              # For automation, we assume the input segmentation is accepted as expert quality.\n              print(f\"Simulating manual correction based on {img_input}...\")\n              shutil.copyfile(seg_input, output_path)\n              print(\"Expert verification complete.\")\n\n          if __name__ == \"__main__\":\n              parser = argparse.ArgumentParser()\n              parser.add_argument(\"--seg_input\", required=True)\n              parser.add_argument(\"--img_input\", required=True)\n              parser.add_argument(\"--output_file\", required=True)\n              args = parser.parse_args()\n              correct(args.seg_input, args.img_input, args.output_file)\n\ninputs:\n  preliminary_segmentation:\n    type: File\n    inputBinding:\n      prefix: --seg_input\n  harmonized_nifti:\n    type: File\n    inputBinding:\n      prefix: --img_input\n\noutputs:\n  expert_segmentation:\n    type: File\n    outputBinding:\n      glob: \"expert_annotated.nii.gz\"\n\narguments:\n  - prefix: --output_file\n    valueFrom: \"expert_annotated.nii.gz\"\n",
    "tool5_metrics.cwl": "#!/usr/bin/env cwl-runner\ncwlVersion: v1.2\nclass: CommandLineTool\n\nlabel: Segmentation Metrics\ndoc: Calculates Dice coefficient between expert and automatic segmentation.\n\nbaseCommand: [\"python\", \"calc_metrics.py\"]\n\nrequirements:\n  DockerRequirement:\n    dockerPull: python:3.9-slim\n  InitialWorkDirRequirement:\n    listing:\n      - entryname: calc_metrics.py\n        entry: |\n          import nibabel as nib\n          import numpy as np\n          import pandas as pd\n          import argparse\n\n          def dice_coefficient(y_true, y_pred):\n              intersection = np.sum(y_true * y_pred)\n              return (2. * intersection) / (np.sum(y_true) + np.sum(y_pred) + 1e-6)\n\n          def run_metrics(expert_path, auto_path, output_csv):\n              expert = nib.load(expert_path).get_fdata() > 0\n              auto = nib.load(auto_path).get_fdata() > 0\n              \n              dice = dice_coefficient(expert, auto)\n              \n              df = pd.DataFrame([{'Metric': 'Dice', 'Value': dice}])\n              df.to_csv(output_csv, index=False)\n              print(f\"Metrics saved to {output_csv}\")\n\n          if __name__ == \"__main__\":\n              parser = argparse.ArgumentParser()\n              parser.add_argument(\"--expert\", required=True)\n              parser.add_argument(\"--auto\", required=True)\n              parser.add_argument(\"--output_csv\", required=True)\n              args = parser.parse_args()\n              run_metrics(args.expert, args.auto, args.output_csv)\n\ninputs:\n  expert_segmentation:\n    type: File\n    inputBinding:\n      prefix: --expert\n  automatic_segmentation:\n    type: File\n    inputBinding:\n      prefix: --auto\n\noutputs:\n  metrics_csv:\n    type: File\n    outputBinding:\n      glob: \"metrics.csv\"\n\narguments:\n  - prefix: --output_csv\n    valueFrom: \"metrics.csv\"\n",
    "workflow.cwl": "#!/usr/bin/env cwl-runner\ncwlVersion: v1.2\nclass: Workflow\n\nlabel: MAMA-MIA Dataset Curation Pipeline\ndoc: Pipeline for converting DICOMs, standardizing, segmenting, manually verifying (simulated), and benchmarking metrics.\n\ninputs:\n  dicom_source_dir:\n    type: Directory\n    doc: Input directory containing DICOM series.\n\nsteps:\n  # Step 1: Convert DICOM to NIfTI\n  convert_dicom:\n    run: tool1_dicom_convert.cwl\n    in:\n      dicom_directory: dicom_source_dir\n    out: [nifti_image]\n\n  # Step 2: Standardize Orientation\n  standardize_image:\n    run: tool2_standardize.cwl\n    in:\n      nifti_image: convert_dicom/nifti_image\n    out: [harmonized_nifti]\n\n  # Step 3: Auto Segmentation (nnU-Net)\n  auto_segmentation:\n    run: tool3_segmentation.cwl\n    in:\n      harmonized_nifti: standardize_image/harmonized_nifti\n    out: [preliminary_segmentation]\n\n  # Step 4: Manual Correction (Simulated)\n  manual_correction:\n    run: tool4_manual_correction.cwl\n    in:\n      preliminary_segmentation: auto_segmentation/preliminary_segmentation\n      harmonized_nifti: standardize_image/harmonized_nifti\n    out: [expert_segmentation]\n\n  # Step 5: Calculate Metrics\n  calculate_metrics:\n    run: tool5_metrics.cwl\n    in:\n      expert_segmentation: manual_correction/expert_segmentation\n      automatic_segmentation: auto_segmentation/preliminary_segmentation\n    out: [metrics_csv]\n\noutputs:\n  final_expert_segmentation:\n    type: File\n    outputSource: manual_correction/expert_segmentation\n  \n  segmentation_metrics:\n    type: File\n    outputSource: calculate_metrics/metrics_csv\n"
  }
}