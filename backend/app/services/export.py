"""
VeriFlow - SDS Export Service
Generates SPARC Dataset Structure compliant ZIP files from execution results.
Per PLAN.md Stage 6 and SPEC.md Section 8.3
"""

import io
import json
import zipfile
from datetime import datetime
from pathlib import Path
from typing import Optional, Dict, Any, List

# Try to import openpyxl for manifest generation
try:
    from openpyxl import Workbook
    XLSX_AVAILABLE = True
except ImportError:
    XLSX_AVAILABLE = False


class SDSExporter:
    """
    Exports execution results as SPARC Dataset Structure (SDS) compliant ZIP.
    
    SDS Structure:
    export_pub_123.zip
    ├── dataset_description.json
    ├── manifest.xlsx
    ├── provenance.json
    └── derivative/
        └── {execution_id}/
            └── {output files}
    """
    
    def __init__(self):
        pass
    
    def generate_dataset_description(
        self,
        execution_id: str,
        workflow_id: str,
        title: str = "VeriFlow Execution Results",
        description: str = "Results generated by VeriFlow workflow execution.",
    ) -> dict:
        """Generate dataset_description.json for the SDS package."""
        return {
            "name": title,
            "description": description,
            "identifier": execution_id,
            "version": "1.0.0",
            "dateCreated": datetime.utcnow().isoformat() + "Z",
            "license": "CC-BY-4.0",
            "keywords": ["VeriFlow", "workflow execution", "medical imaging"],
            "contributors": [
                {
                    "name": "VeriFlow System",
                    "role": "generator",
                }
            ],
            "sources": [
                {
                    "type": "workflow",
                    "identifier": workflow_id,
                }
            ],
        }
    
    def generate_provenance(
        self,
        execution_id: str,
        workflow_id: str,
        inputs: List[Dict[str, Any]],
        outputs: List[Dict[str, Any]],
        node_statuses: Dict[str, Dict[str, Any]],
    ) -> dict:
        """
        Generate provenance.json with wasDerivedFrom relationships.
        Per SPEC.md Section 8.1
        """
        activities = []
        entities = []
        derivations = []
        
        # Add input entities
        for inp in inputs:
            entities.append({
                "id": inp.get("id", f"input_{len(entities)}"),
                "type": "input",
                "path": inp.get("path", "unknown"),
                "format": inp.get("format", "unknown"),
            })
        
        # Add output entities
        for out in outputs:
            output_entity = {
                "id": out.get("id", f"output_{len(entities)}"),
                "type": "output",
                "path": out.get("path", "unknown"),
                "format": out.get("format", "unknown"),
                "generatedBy": out.get("node_id"),
            }
            entities.append(output_entity)
            
            # Create derivation links from inputs to this output
            for inp in inputs:
                if out.get("node_id"):
                    derivations.append({
                        "generatedEntity": output_entity["id"],
                        "usedEntity": inp.get("id", f"input_0"),
                        "activity": out.get("node_id"),
                    })
        
        # Add activities from node executions
        for node_id, status in node_statuses.items():
            activities.append({
                "id": node_id,
                "type": "processing_step",
                "status": status.get("status", "unknown"),
                "startedAt": status.get("started_at"),
                "endedAt": status.get("ended_at"),
            })
        
        return {
            "execution_id": execution_id,
            "workflow_id": workflow_id,
            "generated_at": datetime.utcnow().isoformat() + "Z",
            "provenance": {
                "entities": entities,
                "activities": activities,
                "derivations": derivations,
            },
        }
    
    def generate_manifest_xlsx(self, files: List[Dict[str, Any]]) -> bytes:
        """
        Generate manifest.xlsx per SDS specification.
        Per SPEC.md Section 3.1
        """
        if not XLSX_AVAILABLE:
            # Return empty bytes if openpyxl not available
            return b""
        
        wb = Workbook()
        ws = wb.active
        ws.title = "Manifest"
        
        # Headers per SDS manifest schema
        headers = ["filename", "timestamp", "description", "file type", "additional type"]
        ws.append(headers)
        
        # Add file entries
        for file_info in files:
            ws.append([
                file_info.get("filename", ""),
                file_info.get("timestamp", datetime.utcnow().isoformat()),
                file_info.get("description", "Data file"),
                file_info.get("file_type", "data"),
                file_info.get("additional_type", "application/octet-stream"),
            ])
        
        # Save to bytes
        buffer = io.BytesIO()
        wb.save(buffer)
        buffer.seek(0)
        return buffer.read()
    
    def generate_manifest_csv(self, files: List[Dict[str, Any]]) -> str:
        """
        Generate manifest as CSV fallback if openpyxl not available.
        """
        lines = ["filename,timestamp,description,file type,additional type"]
        for file_info in files:
            line = ",".join([
                file_info.get("filename", ""),
                file_info.get("timestamp", datetime.utcnow().isoformat()),
                file_info.get("description", "Data file"),
                file_info.get("file_type", "data"),
                file_info.get("additional_type", "application/octet-stream"),
            ])
            lines.append(line)
        return "\n".join(lines)
    
    def create_export_zip(
        self,
        execution_id: str,
        workflow_id: str,
        title: str,
        description: str,
        inputs: List[Dict[str, Any]],
        outputs: List[Dict[str, Any]],
        node_statuses: Dict[str, Dict[str, Any]],
        output_file_data: Dict[str, bytes],  # path -> file content
    ) -> bytes:
        """
        Create the complete SDS export ZIP file.
        
        Args:
            execution_id: Unique execution identifier
            workflow_id: Source workflow identifier
            title: Human-readable title
            description: Human-readable description
            inputs: List of input file metadata
            outputs: List of output file metadata
            node_statuses: Node execution status data
            output_file_data: Dict mapping relative paths to file bytes
        
        Returns:
            ZIP file as bytes
        """
        buffer = io.BytesIO()
        
        with zipfile.ZipFile(buffer, 'w', zipfile.ZIP_DEFLATED) as zf:
            # 1. Add dataset_description.json
            dataset_desc = self.generate_dataset_description(
                execution_id=execution_id,
                workflow_id=workflow_id,
                title=title,
                description=description,
            )
            zf.writestr("dataset_description.json", json.dumps(dataset_desc, indent=2))
            
            # 2. Add provenance.json
            provenance = self.generate_provenance(
                execution_id=execution_id,
                workflow_id=workflow_id,
                inputs=inputs,
                outputs=outputs,
                node_statuses=node_statuses,
            )
            zf.writestr("provenance.json", json.dumps(provenance, indent=2))
            
            # 3. Prepare manifest entries
            manifest_files = []
            for out in outputs:
                manifest_files.append({
                    "filename": out.get("path", "unknown"),
                    "timestamp": datetime.utcnow().isoformat(),
                    "description": out.get("description", "Output file"),
                    "file_type": out.get("type", "data"),
                    "additional_type": out.get("format", "application/octet-stream"),
                })
            
            # 4. Add manifest (xlsx or csv)
            if XLSX_AVAILABLE:
                manifest_bytes = self.generate_manifest_xlsx(manifest_files)
                zf.writestr("manifest.xlsx", manifest_bytes)
            else:
                manifest_csv = self.generate_manifest_csv(manifest_files)
                zf.writestr("manifest.csv", manifest_csv)
            
            # 5. Add output files
            for path, content in output_file_data.items():
                # Ensure path is relative and in derivative folder
                rel_path = f"derivative/{execution_id}/{path}"
                zf.writestr(rel_path, content)
        
        buffer.seek(0)
        return buffer.read()


# Singleton instance
sds_exporter = SDSExporter()
