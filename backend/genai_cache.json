{
  "MODEL:gemini-2.5-flash|SYS:87daa587a842e5258cb400e69233560a|TXT:3a994373f566fac590c6844fd21765d5|FILE_HASH:a014f4c2c2564fea25e2e0445a301389": {
    "investigation": {
      "id": "inv_1",
      "title": "An Open-Source End-to-End Pipeline for Generating 3D+t Biventricular Meshes from Cardiac Magnetic Resonance Imaging",
      "description": "Increased interest in digital-twin based healthcare has stimulated recent advancements in personalised biventricular modelling from cardiac magnetic resonance (CMR) imaging. However, there remains no publicly available end-to-end pipeline for generating structured meshes of the heart across the entire cardiac cycle. This paper presents a new pipeline and tests it on CMR data contributed from two centres. The proposed pipeline comprises view classification, segmentation of the left and right ventricular chambers and myocardium, contour generation, and model fitting in a fully automated sequence, requiring only an image directory as input. The use of 3D U-Nets was explored, and found to increase the temporal coherence of resulting meshes compared to 2D U-Nets when evaluated on 10 test cases. The pipeline is available to be deployed across various applications, including digital-twin based simulations, statistical shape and motion analyses, and clinical research. The pipeline\u2014including code, models, and documentation\u2014can be accessed at https://github.com/UOA-Heart-Mechanics-Research/biv-me.",
      "studies": [
        {
          "id": "study_1",
          "title": "Development and Evaluation of an Open-Source End-to-End Pipeline for 3D+t Biventricular Mesh Generation",
          "assays": [
            {
              "id": "assay_1",
              "name": "3D+t Biventricular Mesh Generation from CMR",
              "measurement_type": "Computational Modelling",
              "technology_type": "Cardiac Magnetic Resonance Imaging; Deep Learning; Diffeomorphic Registration",
              "steps": [
                {
                  "id": "step_1",
                  "name": "Data Preparation",
                  "description": "CMR images contributed from two datasets: 200 healthy participants from the UK Biobank and 160 mixed healthy/patient cohort from the CARDIOHANCE study were used as input. Images were manually reviewed and divided into 10 view classes by a single expert observer."
                },
                {
                  "id": "step_2",
                  "name": "View Classification",
                  "description": "A convolutional neural network based on the ResNet50 architecture was trained for 50 epochs using a cross-entropy loss function with an Adam optimiser to automatically predict the view of a CMR image series. Augmentations (flipping, rotation, translation, crop) were applied. The model was trained on 4278 image series, validated on 533, and tested on 520."
                },
                {
                  "id": "step_3",
                  "name": "Cardiac Structure Segmentation",
                  "description": "The nnU-Net framework was used to train segmentation models for each view to automatically label relevant cardiac structures (LV and RV chambers, myocardium). Ground truth labels for all frames were generated by 'overfitting' a 2D nnU-Net model to manual segmentations at end-diastole (ED) and end-systole (ES) frames, then applying it to other frames, followed by manual correction. Default 3D nnU-Net models were trained for 500 epochs using these 2D+t reference segmentations. For comparison, 2D nnU-Net models were trained using original manual segmentations at ED and ES."
                },
                {
                  "id": "step_4",
                  "name": "Contour Set Generation",
                  "description": "Contour sets, including endocardial, atrial and epicardial borders, and key landmarks (apex, RV inserts, mitral valve, tricuspid valve, aortic valve, pulmonary valve), were generated from the segmented labels for each frame in the cardiac cycle."
                },
                {
                  "id": "step_5",
                  "name": "Biventricular Mesh Fitting",
                  "description": "Using the generated contour sets, biventricular meshes were fitted for each time frame using a previously described iterative diffeomorphic registration algorithm. A multi-class subdivision surface template mesh was refined to each contour set with an implicit linear least squares fit and an explicit diffeomorphic fit to yield a structured point-correspondent mesh across the cardiac cycle. Outputs included epicardial (2502 vertices), LV endocardial (1572 vertices), and RV endocardial meshes (1956 vertices) for each frame."
                },
                {
                  "id": "step_6",
                  "name": "Pipeline Output Evaluation",
                  "description": "For each case, volumes and masses for the LV and RV were calculated from the generated biventricular meshes. Temporal coherence was evaluated by the smoothness of volume-time traces (calculated using a low-pass filter) and consistency of mass-time traces. Smoothness and mass consistency values were averaged across 10 evaluation cases and compared between 2D and 2D+t segmentation models using paired sample t-tests."
                }
              ]
            }
          ]
        }
      ]
    },
    "identified_tools": [
      "ResNet50",
      "Adam optimiser",
      "nnU-Net framework",
      "Iterative diffeomorphic registration algorithm",
      "Low-pass filter",
      "Paired sample t-tests"
    ],
    "identified_models": [
      "View classification model (ResNet50-based CNN)",
      "2D nnU-Net segmentation models",
      "3D nnU-Net segmentation models",
      "Multi-class subdivision surface template mesh"
    ],
    "identified_measurements": [
      "View prediction performance metrics (F-scores, TPR, FPR, TNR, FNR)",
      "Segmentation performance (Dice coefficient)",
      "Left Ventricular (LV) volume",
      "Right Ventricular (RV) volume",
      "Left Ventricular (LV) mass",
      "Right Ventricular (RV) mass",
      "Temporal coherence (smoothness of volume-time traces)",
      "Temporal coherence (consistency of mass-time traces)",
      "Processing time per case"
    ],
    "confidence_scores": {
      "investigation": 5,
      "studies": 5,
      "assays": 5,
      "steps": 5,
      "identified_tools": 5,
      "identified_models": 5,
      "identified_measurements": 5
    }
  },
  "MODEL:gemini-2.5-flash|SYS:87daa587a842e5258cb400e69233560a|TXT:3a994373f566fac590c6844fd21765d5|FILE_HASH:50b22a5f6906ad27d562bbaff7642c00": {
    "investigation": {
      "id": "inv_1",
      "title": "A large-scale multicenter breast cancer DCE-MRI benchmark dataset with expert segmentations",
      "description": "Artificial Intelligence (AI) research in breast cancer Magnetic Resonance Imaging (MRI) faces challenges due to limited expert-labeled segmentations. To address this, we present a multicenter dataset of 1506 pre-treatment T1-weighted dynamic contrast-enhanced MRI cases, including expert annotations of primary tumors and non-mass-enhanced regions. The dataset integrates imaging data from four collections in The Cancer Imaging Archive (TCIA), where only 163 cases with expert segmentations were initially available. To facilitate the annotation process, a deep learning model was trained to produce preliminary segmentations for the remaining cases. These were subsequently corrected and verified by 16 breast cancer experts (averaging 9 years of experience), creating a fully annotated dataset. Additionally, the dataset includes 49 harmonized clinical and demographic variables, as well as pre-trained weights for a baseline nnU-Net model trained on the annotated data. This resource addresses a critical gap in publicly available breast cancer datasets, enabling the development, validation, and benchmarking of advanced deep learning models, thus driving progress in breast cancer diagnostics, treatment response prediction, and personalized care."
    },
    "studies": [
      {
        "id": "study_1",
        "title": "Creation and Annotation of a Multicenter Breast Cancer DCE-MRI Benchmark Dataset",
        "assays": [
          {
            "id": "assay_1",
            "name": "DCE-MRI Data Collection and Segmentation",
            "measurement_type": "Image Segmentation",
            "technology_type": "Magnetic Resonance Imaging (MRI)",
            "steps": [
              {
                "id": "step_1",
                "name": "Data Collection from TCIA",
                "description": "Pre-treatment T1-weighted Dynamic Contrast-Enhanced MRI (DCE-MRI) cases were collected from four public collections (I-SPY1, I-SPY2, NACT, DUKE) within The Cancer Imaging Archive (TCIA). Initial selection criteria included cases that underwent Neoadjuvant Chemotherapy (NAC) treatment, had pre-treatment DCE-MRI, and had available clinical data (Pathological Complete Response (pCR) or survival status). An initial quality control step discarded cases without sufficient contrast enhancement or with artifacts, resulting in a final dataset of 1506 cases."
              },
              {
                "id": "step_2",
                "name": "Data Harmonization",
                "description": "Clinical (21 variables), demographic (6 variables), and imaging (22 parameters) data from the selected cases were consolidated and harmonized into a single table. The dataset folder structure was standardized for easy retrieval, and image orientation was standardized (axial MRIs reoriented to LAS, sagittal MRIs to PSR). No additional preprocessing steps like bias field correction, image normalization, or voxel resampling were applied to the dataset itself, but scripts for these are provided for users."
              },
              {
                "id": "step_3",
                "name": "Volume of Interest (VOI) Definition",
                "description": "A 3D rectangular bounding box (Volume of Interest, VOI) was manually drawn to encompass the entire enhanced region for each case. For cases where bounding box coordinates were not directly available, an approximate VOI was created by filtering Percent Enhancement (PE) and Signal Enhancement Ratio (SER) images using specific thresholds to derive the Functional Tumor Volume (FTV)."
              },
              {
                "id": "step_4",
                "name": "Preliminary Automatic Segmentation",
                "description": "A state-of-the-art deep learning model (nnU-Net framework) was initially trained using a set of 331 existing expert segmentations from DUKE and TCGA-BRCA collections. This trained model was then used to produce preliminary automatic segmentations for the remaining cases in the dataset. Preprocessing for model training included cropping images to the VOI, resampling to 1x1x1 mm\u00b3 isotropic pixel spacing, and data augmentation (adding 25% pixel margin to VOI, random flipping)."
              },
              {
                "id": "step_5",
                "name": "Visual Quality Control of Preliminary Segmentations",
                "description": "Two expert breast radiologists visually assessed the quality of all preliminary automatic segmentations using an in-house graphical user interface (GUI). For each case, three 2D slices from the first post-contrast image (axial, sagittal, coronal) were displayed with segmentation contours. Segmentations were categorized into four quality categories: 'Good', 'Acceptable', 'Poor', or 'Missed'."
              },
              {
                "id": "step_6",
                "name": "Expert Manual Correction of Segmentations",
                "description": "A total of 16 breast cancer experts (radiologists, surgical oncologist, medical physicist) manually corrected and verified all preliminary automatic segmentations, including those initially rated as 'Good'. Experts were blinded to the preliminary quality categories to prevent bias. The Mango viewer was used for corrections, following specific guidelines: segment only the primary tumor, avoid healthy tissue, exclude tissue markers/clips, include tumor necrosis, exclude intra-mammary lymph nodes, and ensure consistency across all views. This process resulted in 1506 expert-annotated segmentations."
              }
            ]
          }
        ]
      }
    ],
    "identified_tools": [
      "The Cancer Imaging Archive (TCIA)",
      "nnU-Net framework",
      "Mango viewer",
      "pandas library",
      "matplotlib",
      "pycad Python library",
      "seg-metrics Python library",
      "nibabel",
      "SimpleITK"
    ],
    "identified_models": [
      "Deep learning model (nnU-Net) for preliminary segmentations",
      "Baseline nnU-Net model trained on expert segmentations"
    ],
    "identified_measurements": [
      "T1-weighted dynamic contrast-enhanced MRI (DCE-MRI)",
      "Expert annotations of primary tumors",
      "Expert annotations of non-mass-enhanced regions",
      "Clinical variables (e.g., pathological complete response (pCR), survival status, tumor subtype)",
      "Demographic variables (e.g., age, ethnicity, BMI)",
      "Imaging parameters (e.g., acquisition plane, magnetic field strength, fat suppression, scanner manufacturer/model, image matrix, number of phases, number of slices, slice thickness, pixel spacing)",
      "Segmentation quality scores (Good, Acceptable, Poor, Missed)",
      "Dice Similarity Coefficient (DSC)",
      "95 percentile Hausdorff Distance (HD)",
      "Functional Tumor Volume (FTV)",
      "Percent Enhancement (PE) image",
      "Signal Enhancement Ratio (SER) image"
    ],
    "confidence_scores": {
      "investigation": 5,
      "studies": 5,
      "assays": 5,
      "steps": 5,
      "identified_tools": 4,
      "identified_models": 4,
      "identified_measurements": 5
    }
  },
  "MODEL:gemini-flash-latest|SYS:87daa587a842e5258cb400e69233560a|TXT:3a994373f566fac590c6844fd21765d5|FILE_HASH:50b22a5f6906ad27d562bbaff7642c00": {
    "investigation": {
      "id": "inv_1",
      "title": "A large-scale multicenter breast cancer DCE-MRI benchmark dataset with expert segmentations",
      "description": "A multicenter dataset (MAMA-MIA) of 1506 pre-treatment T1-weighted dynamic contrast-enhanced MRI (DCE-MRI) cases, including expert annotations of primary tumors and non-mass-enhanced regions. The dataset integrates imaging data from four collections in The Cancer Imaging Archive (TCIA). Preliminary segmentations generated by a deep learning model were corrected and verified by 16 breast cancer experts, resulting in a fully annotated dataset. The resource includes 49 harmonized clinical and demographic variables, 22 imaging parameters, and pre-trained weights for a baseline nnU-Net model, serving as a benchmark for advanced deep learning models in breast cancer diagnostics and treatment response prediction.",
      "studies": [
        {
          "id": "study_1",
          "title": "MAMA-MIA Dataset Construction and Expert Annotation",
          "assays": [
            {
              "id": "assay_1",
              "name": "DCE-MRI Tumor Segmentation and Quality Control Pipeline",
              "measurement_type": "Segmentation",
              "technology_type": "Dynamic Contrast-Enhanced Magnetic Resonance Imaging (DCE-MRI)",
              "steps": [
                {
                  "id": "step_1",
                  "name": "Data Sourcing and Initial Filtering",
                  "description": "Collect pre-treatment T1-weighted DCE-MRI cases from four public TCIA collections (I-SPY1, I-SPY2, DUKE, NACT) that underwent Neoadjuvant Chemotherapy (NAC) and had corresponding clinical data (pCR or survival status) available."
                },
                {
                  "id": "step_2",
                  "name": "Initial Image Quality Control (QC)",
                  "description": "Experts excluded cases lacking sufficient contrast enhancement or those with artifacts that significantly impeded accurate cancer segmentation, resulting in the final 1506 cases for the MAMA-MIA dataset."
                },
                {
                  "id": "step_3",
                  "name": "Data Harmonization and Standardization",
                  "description": "Consolidate and harmonize 21 clinical variables, 6 demographic variables, and 22 imaging parameters into a single table. Standardize the dataset folder structure, file naming, and image orientation (Axial MRIs to LAS, Sagittal MRIs to PSR) for computational analysis."
                },
                {
                  "id": "step_4",
                  "name": "Volume of Interest (VOI) Definition",
                  "description": "Define a 3D rectangular bounding box (VOI) manually drawn to encompass the entire enhanced region (primary tumor or non-mass-enhanced area). Functional Tumor Volume (FTV) analysis masks were used where available, or approximate VOIs were created using filtering steps on SER/PE images."
                },
                {
                  "id": "step_5",
                  "name": "Preliminary Segmentation Model Training",
                  "description": "Train a standard nnU-Net deep learning model using 331 external expert segmentations (from DUKE and TCGA-BRCA) on cropped VOIs, preprocessed with resampling to 1x1x1 mm\u00b3 isotropic pixel spacing."
                },
                {
                  "id": "step_6",
                  "name": "Preliminary Automatic Segmentation Generation",
                  "description": "Generate preliminary automatic segmentations for all 1506 cases using the trained nnU-Net model. Segmentations were up-sampled and mapped back to the original image space."
                },
                {
                  "id": "step_7",
                  "name": "Visual Quality Control (QC) of Automatic Segmentations",
                  "description": "Two expert breast radiologists visually assessed all 1506 preliminary automatic segmentations using a GUI, categorizing them into four quality categories: Good, Acceptable, Poor, or Missed."
                },
                {
                  "id": "step_8",
                  "name": "Expert Manual Correction and Verification",
                  "description": "16 breast cancer experts manually corrected and verified the preliminary automatic segmentations for all 1506 cases using the Mango viewer. Experts were instructed to segment only the primary lesion within the VOI."
                },
                {
                  "id": "step_9",
                  "name": "Baseline Model Training and Weight Release",
                  "description": "Train a baseline nnU-Net model using the final 1506 expert segmentations (full images, 5-fold cross-validation) and release the pre-trained weights as an additional contribution."
                },
                {
                  "id": "step_10",
                  "name": "Metric Calculation",
                  "description": "Compute the Dice Similarity Coefficient (DSC) and 95 percentile Hausdorff Distance (HD) between the preliminary automatic segmentations and the final expert segmentations."
                }
              ]
            }
          ]
        }
      ]
    },
    "identified_tools": [
      "The Cancer Imaging Archive (TCIA)",
      "nnU-Net (Deep Learning Framework)",
      "nibabel (Python library for medical imaging processing)",
      "SimpleITK (Software for medical imaging data processing)",
      "Mango viewer (Tool for manual segmentation correction)",
      "pycad Python library (Used for DICOM to NIfTI transformation)",
      "seg-metrics 1.2.7 Python library (Used for computing DSC and HD)",
      "pandas library (Used for data filtering and visualization)",
      "matplotlib (Used for plotting MRI images)"
    ],
    "identified_models": [
      "Deep learning model (nnU-Net) for preliminary automatic segmentation",
      "Baseline nnU-Net tumor segmentation model (Trained on expert segmentations)"
    ],
    "identified_measurements": [
      "DCE-MRI cases (1506 pre-treatment T1-weighted)",
      "Expert Segmentations (Primary tumors and non-mass-enhanced areas)",
      "Automatic Segmentations (Preliminary)",
      "Clinical Variables (21 variables, including pCR and survival status)",
      "Demographic Variables (6 variables, including age and ethnicity)",
      "Imaging Parameters (22 parameters, including acquisition times)",
      "Segmentation Quality Scores (Good, Acceptable, Poor, Missed)",
      "Dice Similarity Coefficient (DSC)",
      "95 percentile Hausdorff Distance (HD)"
    ],
    "confidence_scores": {}
  },
  "MODEL:gemini-flash-lite-latest|SYS:87daa587a842e5258cb400e69233560a|TXT:3a994373f566fac590c6844fd21765d5|FILE_HASH:50b22a5f6906ad27d562bbaff7642c00": {
    "investigation": {
      "id": "inv_1",
      "title": "A large-scale multicenter breast cancer DCE-MRI benchmark dataset with expert segmentations",
      "description": "Artificial Intelligence (AI) research in breast cancer Magnetic Resonance Imaging (MRI) faces challenges due to limited expert-labeled segmentations. We present a multicenter dataset of 1506 pre-treatment T1-weighted dynamic contrast-enhanced MRI cases, including expert annotations of primary tumors and non-mass-enhanced regions. The dataset integrates imaging data from four collections in The Cancer Imaging Archive (TCIA). A deep learning model was trained to produce preliminary segmentations for the remaining cases, which were subsequently corrected and verified by 16 breast cancer experts. The dataset also includes 49 harmonized clinical and demographic variables, as well as pre-trained weights for a baseline nnU-Net model.",
      "studies": [
        {
          "id": "study_mama_mia",
          "title": "MAMA-MIA Dataset Construction and Harmonization",
          "assays": [
            {
              "id": "assay_data_collection",
              "name": "Data Collection and Harmonization",
              "measurement_type": "Imaging Data Acquisition and Curation",
              "technology_type": "DCE-MRI",
              "steps": [
                {
                  "id": "step_1_collection",
                  "name": "Initial Data Collection",
                  "description": "Collected pre-treatment T1-weighted DCE-MRI cases from four public collections in TCIA (I-SPY1, I-SPY2, NACT-Pilot, Duke-Breast-Cancer-MRI), sourcing a total of 2193 cases."
                },
                {
                  "id": "step_2_selection",
                  "name": "Selection Criteria Application",
                  "description": "Applied selection criteria: 1) DCE-MRI series acquired before NAC treatment started (timepoint T0). 2) Cases with available clinical data on treatment response (pCR) or survival status. 3) Expert quality control to exclude cases without sufficient contrast enhancement or with artifacts impeding segmentation. Resulted in 1506 included cases."
                },
                {
                  "id": "step_3_harmonization",
                  "name": "Data Harmonization",
                  "description": "Consolidated and harmonized clinical and imaging data into a single table, including 21 clinical variables, 6 demographic variables, and 22 imaging parameters. Standardized folder structure and image orientation (Axial to LAS, Sagittal to PSR)."
                }
              ]
            },
            {
              "id": "assay_segmentation_generation",
              "name": "Expert Segmentation Generation",
              "measurement_type": "Image Segmentation",
              "technology_type": "Deep Learning Model + Expert Correction",
              "steps": [
                {
                  "id": "step_4_prelim_seg",
                  "name": "Preliminary Automatic Segmentation Training and Inference",
                  "description": "Trained an nnU-Net model on 331 existing expert segmentations (from DUKE and TCGA-BRCA) to produce preliminary segmentations for the remaining cases. Preprocessing included cropping to VOI and resampling to 1x1x1 mm\u00b3 isotropic spacing."
                },
                {
                  "id": "step_5_quality_control",
                  "name": "Visual Quality Control of Preliminary Segmentations",
                  "description": "Two expert radiologists visually inspected the preliminary automatic segmentations on 2D slices (axial, sagittal, coronal) from the first post-contrast image and categorized them as Good, Acceptable, Poor, or Missed."
                },
                {
                  "id": "step_6_expert_correction",
                  "name": "Expert Manual Correction",
                  "description": "16 experts manually corrected, inspected, and verified the preliminary automatic segmentations for 1095 missing cases (plus 411 existing expert segmentations were also reviewed). Experts were instructed to segment only the primary lesion within the Volume of Interest (VOI), defined as a 3D rectangular box encompassing the entire enhanced region."
                }
              ]
            }
          ]
        }
      ],
      "identified_tools": [
        {
          "name": "nnU-Net",
          "description": "Deep learning framework used for training the preliminary automatic tumor segmentation model and for which pre-trained weights are provided.",
          "type": "Software/Algorithm"
        },
        {
          "name": "Mango viewer",
          "description": "Tool selected by experts to correct the automatic segmentations.",
          "type": "Software/Viewer"
        },
        {
          "name": "pycad",
          "description": "Python library used to transform original DICOM images from TCIA to NIfTI format.",
          "type": "Software/Library"
        },
        {
          "name": "seg-metrics 1.2.7",
          "description": "Python library used to compute metrics like Dice coefficient and 95% Hausdorff Distance.",
          "type": "Software/Library"
        },
        {
          "name": "nibabel",
          "description": "Software used for processing medical imaging data, aligned with orientation standardization decisions.",
          "type": "Software/Library"
        },
        {
          "name": "SimpleITK",
          "description": "Software used for processing medical imaging data, aligned with orientation standardization decisions.",
          "type": "Software/Library"
        }
      ],
      "identified_models": [
        {
          "name": "Baseline nnU-Net tumor segmentation model (pre-trained weights)",
          "description": "A vanilla nnU-Net model trained on the 1506 expert segmentations of primary tumors for inference or fine-tuning.",
          "type": "Machine Learning Model"
        }
      ],
      "identified_measurements": [
        {
          "name": "Primary Tumor Segmentation Mask",
          "description": "Expert-corrected 3D segmentation mask for the primary lesion in pre-treatment DCE-MRI.",
          "type": "Segmentation Mask"
        },
        {
          "name": "Non-Mass-Enhanced Region Segmentation Mask",
          "description": "Expert-corrected 3D segmentation mask for non-mass-enhanced areas.",
          "type": "Segmentation Mask"
        },
        {
          "name": "Functional Tumor Volume (FTV)",
          "description": "Tumor volume derived by filtering percent enhancement (PE) and signal enhancement ratio (SER) images, used as input for preliminary automatic segmentation.",
          "type": "Volumetric Measurement"
        },
        {
          "name": "Volume of Interest (VOI)",
          "description": "3D rectangular box manually drawn to encompass the entire enhanced region.",
          "type": "Bounding Box/Region of Interest"
        },
        {
          "name": "Dice Similarity Coefficient (DSC)",
          "description": "Metric used to evaluate segmentation quality between automatic and expert segmentations.",
          "type": "Image Quality Metric"
        },
        {
          "name": "95 percentile Hausdorff Distance (HD)",
          "description": "Metric used to evaluate segmentation alignment between automatic and expert segmentations.",
          "type": "Image Quality Metric"
        }
      ],
      "confidence_scores": {
        "Data_Integration": "High",
        "Segmentation_Extraction": "High (due to explicit workflow description and figures)",
        "Metadata_Extraction": "High (detailed tables provided)"
      }
    }
  },
  "MODEL:gemini-2.5-flash-lite|SYS:87daa587a842e5258cb400e69233560a|TXT:3a994373f566fac590c6844fd21765d5|FILE_HASH:50b22a5f6906ad27d562bbaff7642c00": {
    "investigation": {
      "id": "inv_1",
      "title": "A large-scale multicenter breast cancer DCE-MRI benchmark dataset with expert segmentations",
      "description": "Artificial Intelligence (AI) research in breast cancer Magnetic Resonance Imaging (MRI) faces challenges due to limited expert-labeled segmentations. To address this, we present a multicenter dataset of 1506 pre-treatment T1-weighted dynamic contrast-enhanced MRI cases, including expert annotations of primary tumors and non-mass-enhanced regions. The dataset integrates imaging data from four collections in The Cancer Imaging Archive (TCIA), where only 163 cases with expert segmentations were initially available. To facilitate the annotation process, a deep learning model was trained to produce preliminary segmentations for the remaining cases. These were subsequently corrected and verified by 16 breast cancer experts (averaging 9 years of experience), creating a fully annotated dataset. Additionally, the dataset includes 49 harmonized clinical and demographic variables, as well as pre-trained weights for a baseline nnU-Net model trained on the annotated data. This resource addresses a critical gap in publicly available breast cancer datasets, enabling the development, validation, and benchmarking of advanced deep learning models, thus driving progress in breast cancer diagnostics, treatment response prediction, and personalized care.",
      "studies": [
        {
          "id": "study_1",
          "title": "MAMA-MIA Dataset",
          "assays": [
            {
              "id": "assay_1",
              "name": "DCE-MRI Image Acquisition and Segmentation",
              "measurement_type": "Image Segmentation",
              "technology_type": "MRI",
              "steps": [
                {
                  "id": "step_1",
                  "name": "Data Collection",
                  "description": "Collection of pre-treatment T1-weighted DCE-MRI cases from four different collections in TCIA: DUKE, ISPY1, ISPY2, and NACT. A total of 1506 cases were sourced."
                },
                {
                  "id": "step_2",
                  "name": "Data Harmonization",
                  "description": "Consolidation and harmonization of clinical and imaging data into a single table, including 21 clinical variables, 6 demographic variables, and 22 imaging parameters. Standardization of folder structure and naming for easy retrieval."
                },
                {
                  "id": "step_3",
                  "name": "Preliminary Segmentation",
                  "description": "A deep learning model (nnU-Net) was trained to produce preliminary segmentations for the primary tumors and non-mass-enhanced regions. The training dataset comprised 331 expert-validated segmentations from DUKE and TCGA-BRCA collections. Preprocessing steps included cropping to the VOI and resampling to 1x1x1 mm\u00b3 isotropic pixel spacing. Data augmentation involved adding a 25% pixel margin to the VOI and applying random flipping."
                },
                {
                  "id": "step_4",
                  "name": "Expert Correction and Verification",
                  "description": "16 breast cancer experts manually corrected, inspected, and verified the preliminary segmentations. Guidelines for segmentation included segmenting only the primary tumor, avoiding healthy tissue in non-mass enhanced cases, excluding tissue markers, including tumor necrosis, and not including intra-mammary lymph nodes. The Mango viewer was used for corrections."
                },
                {
                  "id": "step_5",
                  "name": "Quality Control",
                  "description": "Two expert radiologists evaluated the quality of the preliminary automatic segmentations using a graphical user interface (GUI). Cases were categorized as Good, Acceptable, Poor, or Missed. All cases, including those rated as Good, were sent for manual correction in a blinded approach."
                },
                {
                  "id": "step_6",
                  "name": "Dataset Preparation for Analysis",
                  "description": "No additional preprocessing steps such as bias field correction, image normalization, or voxel resampling were applied to the final dataset to preserve image resolution and potentially affect model performance. Researchers can tailor these procedures to their use cases."
                }
              ]
            }
          ]
        }
      ]
    },
    "identified_tools": [
      {
        "id": "tool_1",
        "name": "nnU-Net",
        "description": "A deep learning framework used for automatic segmentation."
      },
      {
        "id": "tool_2",
        "name": "Mango viewer",
        "description": "A tool selected for manual correction of segmentations."
      },
      {
        "id": "tool_3",
        "name": "pycad",
        "description": "Python library used to transform DICOM images to NIfTI format."
      },
      {
        "id": "tool_4",
        "name": "seg-metrics",
        "description": "Python library used to compute Dice coefficient and 95% Hausdorff Distance."
      }
    ],
    "identified_models": [
      {
        "id": "model_1",
        "name": "nnU-Net Segmentation Model",
        "description": "A baseline nnU-Net model trained on the 1506 expert segmentations of primary tumors. Pre-trained weights are provided."
      }
    ],
    "identified_measurements": [
      {
        "id": "measurement_1",
        "name": "Primary Tumor Segmentation",
        "description": "Expert-corrected segmentations of primary tumors."
      },
      {
        "id": "measurement_2",
        "name": "Non-mass-enhanced Region Segmentation",
        "description": "Expert-corrected segmentations of non-mass-enhanced regions."
      },
      {
        "id": "measurement_3",
        "name": "Clinical and Demographic Variables",
        "description": "49 harmonized clinical and demographic variables, including age, ethnicity, BMI, implants, bilateral cancer, multifocal cancer, tumor subtype, and pCR."
      },
      {
        "id": "measurement_4",
        "name": "Imaging Parameters",
        "description": "22 imaging parameters, including acquisition plane, magnetic field strength, fat suppression, scanner manufacturer and model, image matrix, number of phases, number of slices, slice thickness, and pixel spacing."
      },
      {
        "id": "measurement_5",
        "name": "Preliminary Automatic Segmentation Quality Scores",
        "description": "Quality scores assigned by two expert radiologists to preliminary automatic segmentations."
      },
      {
        "id": "measurement_6",
        "name": "Dice Similarity Coefficient (DSC)",
        "description": "Metric used to evaluate segmentation accuracy."
      },
      {
        "id": "measurement_7",
        "name": "Hausdorff Distance (HD)",
        "description": "Metric used to evaluate segmentation accuracy."
      }
    ],
    "confidence_scores": {}
  },
  "MODEL:gemini-2.5-flash-preview-09-2025|SYS:87daa587a842e5258cb400e69233560a|TXT:3a994373f566fac590c6844fd21765d5|FILE_HASH:50b22a5f6906ad27d562bbaff7642c00": {
    "investigation": {
      "id": "inv_1",
      "title": "A large-scale multicenter breast cancer DCE-MRI benchmark dataset with expert segmentations",
      "description": "This resource presents the MAMA-MIA multicenter dataset of 1506 pre-treatment T1-weighted dynamic contrast-enhanced MRI cases, including expert annotations of primary tumors and non-mass-enhanced regions. The dataset integrates imaging data from four collections in The Cancer Imaging Archive (TCIA). Preliminary segmentations were generated using a deep learning model and subsequently corrected and verified by 16 breast cancer experts. The dataset includes 49 harmonized clinical and demographic variables, as well as pre-trained weights for a baseline nnU-Net model, addressing a critical gap in publicly available breast cancer datasets for benchmarking advanced deep learning models.",
      "studies": [
        {
          "id": "study_1",
          "title": "Creation and Harmonization of the MAMA-MIA Breast Cancer DCE-MRI Dataset",
          "assays": [
            {
              "id": "assay_1",
              "name": "Dynamic Contrast-Enhanced Magnetic Resonance Imaging (DCE-MRI) Segmentation Workflow",
              "measurement_type": "Segmentation and Clinical Data Acquisition",
              "technology_type": "Magnetic Resonance Imaging (MRI)",
              "steps": [
                {
                  "id": "step_1",
                  "name": "Data Collection from Public Sources",
                  "description": "Gather all available open-access DCE-MRI studies of breast cancer patients who underwent Neoadjuvant Chemotherapy (NAC) treatment from four TCIA collections (I-SPY1, I-SPY2, NACT, DUKE), sourcing a total of 2193 cases."
                },
                {
                  "id": "step_2",
                  "name": "Pre-treatment DCE-MRI Selection",
                  "description": "Select only DCE-MRI series acquired at the time of diagnosis and before NAC treatment started (timepoint T0)."
                },
                {
                  "id": "step_3",
                  "name": "Clinical Data Filtering",
                  "description": "Exclude cases lacking information on treatment response, specifically Pathologic Complete Response (pCR) to NAC or five-year survival status."
                },
                {
                  "id": "step_4",
                  "name": "Initial Expert Quality Control (QC)",
                  "description": "Experts discarded cases without sufficient contrast enhancement or those with artifacts that significantly impeded accurate cancer segmentation, resulting in the final 1506 cases for the MAMA-MIA dataset."
                },
                {
                  "id": "step_5",
                  "name": "Data Harmonization and Consolidation",
                  "description": "Consolidate and harmonize clinical (21 variables, including pCR) and imaging data (22 parameters) across the four collections into a single table, along with 6 demographic variables."
                },
                {
                  "id": "step_6",
                  "name": "Image Orientation Standardization",
                  "description": "Standardize image orientation: Axial MRIs were reoriented to the LAS (left-anterior-superior) coordinate system, and sagittal MRIs were reoriented to the PSR (posterior-superior-right) coordinate system."
                },
                {
                  "id": "step_7",
                  "name": "Volume of Interest (VOI) Definition",
                  "description": "Define the 3D rectangular Volume of Interest (VOI) manually to encompass the entire enhanced region (primary tumor or non-mass-enhanced area). If analysis masks (FTV) were unavailable, an approximate VOI was created using filtering steps applied to SER and PE images."
                },
                {
                  "id": "step_8",
                  "name": "Preliminary Segmentation Model Training",
                  "description": "A standard state-of-the-art nnU-Net deep learning model was trained using 331 expert-validated segmentations from DUKE and TCGA-BRCA collections to generate preliminary annotations."
                },
                {
                  "id": "step_9",
                  "name": "Preliminary Automatic Segmentation Generation",
                  "description": "The trained nnU-Net model produced preliminary segmentations for the 1506 cases. Images were cropped to the VOI and resampled to 1 x 1 x 1 mm\u00b3 isotropic pixel spacing prior to segmentation."
                },
                {
                  "id": "step_10",
                  "name": "Visual Quality Control of Preliminary Segmentations",
                  "description": "Two expert breast radiologists visually assessed all 1506 preliminary automatic segmentations using a GUI, categorizing them into four quality categories: Good, Acceptable, Poor, or Missed."
                },
                {
                  "id": "step_11",
                  "name": "Expert Manual Correction and Verification",
                  "description": "A total of 16 experts manually corrected, inspected, and verified all 1506 preliminary automatic segmentations (especially the 1095 missing cases) using the Mango viewer, resulting in the final expert segmentations of primary tumors and non-mass-enhanced areas."
                },
                {
                  "id": "step_12",
                  "name": "Folder Structure Standardization",
                  "description": "The dataset folder structure was standardized for easy retrieval and harmonized to support plug-and-play AI training, including separate folders for images, expert segmentations, and automatic segmentations."
                },
                {
                  "id": "step_13",
                  "name": "Baseline Segmentation Model Training and Weight Release",
                  "description": "Pre-trained weights of a baseline nnU-Net tumor segmentation model were generated by training the model on the 1506 final expert segmentations using 5-fold cross-validation, z-scoring, and isotropic resampling."
                }
              ]
            }
          ]
        }
      ]
    },
    "identified_tools": [
      "TCIA (The Cancer Imaging Archive)",
      "nnU-Net (Segmentation Framework)",
      "GUI (Graphical User Interface)",
      "Mango viewer",
      "pandas library",
      "matplotlib",
      "pycad Python library",
      "seg-metrics 1.2.7 Python library",
      "nibabel",
      "SimpleITK"
    ],
    "identified_models": [
      "nnU-Net Segmentation Model (Preliminary)",
      "Baseline nnU-Net Tumor Segmentation Model"
    ],
    "identified_measurements": [
      "DCE-MRI (Dynamic Contrast-Enhanced Magnetic Resonance Imaging)",
      "T1-weighted DCE-MRI",
      "Expert Segmentations (Primary tumors and non-mass-enhanced regions)",
      "Preliminary Automatic Segmentations",
      "Clinical Variables (e.g., pCR, survival status)",
      "Demographic Variables (e.g., age, ethnicity)",
      "Imaging Parameters (e.g., acquisition times, slice thickness)",
      "Functional Tumor Volume (FTV)",
      "Dice Similarity Coefficient (DSC)",
      "95 percentile Hausdorff Distance (HD)",
      "Cohen's Kappa"
    ],
    "confidence_scores": {}
  },
  "MODEL:gemini-2.5-flash-lite-preview-09-2025|SYS:87daa587a842e5258cb400e69233560a|TXT:3a994373f566fac590c6844fd21765d5|FILE_HASH:50b22a5f6906ad27d562bbaff7642c00": {
    "investigation": {
      "id": "inv_1",
      "title": "A large-scale multicenter breast cancer DCE-MRI benchmark dataset with expert segmentations",
      "description": "Artificial Intelligence (AI) research in breast cancer Magnetic Resonance Imaging (MRI) faces challenges due to limited expert-labeled segmentations. We present a multicenter dataset of 1506 pre-treatment T1-weighted dynamic contrast-enhanced MRI cases, including expert annotations of primary tumors and non-mass-enhanced regions. The dataset integrates imaging data from four collections in The Cancer Imaging Archive (TCIA). A deep learning model was trained to produce preliminary segmentations for the remaining cases, which were subsequently corrected and verified by 16 breast cancer experts. The resource includes 49 harmonized clinical and demographic variables, as well as pre-trained weights for a baseline nnU-Net model.",
      "studies": [
        {
          "id": "study_mama_mia",
          "title": "MAMA-MIA Dataset Curation and Harmonization",
          "assays": [
            {
              "id": "assay_data_collection",
              "name": "Data Collection and Harmonization",
              "measurement_type": "Imaging Data Curation",
              "technology_type": "DCE-MRI Acquisition",
              "steps": [
                {
                  "id": "step_1_collect",
                  "name": "Data Collection from TCIA",
                  "description": "Collected pre-treatment T1-weighted DCE-MRI cases from four public collections in TCIA: I-SPY1 (171 cases), I-SPY2 (980 cases), NACT-Pilot (64 cases), and Duke-Breast-Cancer-MRI (291 cases), totaling 1506 cases after exclusion criteria (e.g., lack of clinical outcome data, poor contrast enhancement, artifacts)."
                },
                {
                  "id": "step_2_harmonize_clinical",
                  "name": "Harmonization of Clinical and Imaging Data",
                  "description": "Consolidated and harmonized clinical and imaging data into a single table, including 21 clinical variables, 6 demographic variables, and 22 imaging parameters. Standardized naming and folder structure for all sequences."
                },
                {
                  "id": "step_3_standardize_orientation",
                  "name": "Image Orientation Standardization",
                  "description": "Axial MRIs were reoriented to the LAS (left-anterior-superior) coordinate system, while sagittal MRIs were reoriented to the PSR (posterior-superior-right) coordinate system."
                }
              ]
            },
            {
              "id": "assay_segmentation_pipeline",
              "name": "Expert Segmentation Generation",
              "measurement_type": "Image Segmentation",
              "technology_type": "Deep Learning Model + Expert Correction",
              "steps": [
                {
                  "id": "step_4_prelim_segmentation",
                  "name": "Preliminary Automatic Segmentation",
                  "description": "Trained a baseline nnU-Net model on 331 existing expert segmentations (from DUKE and TCGA-BRCA) to produce preliminary segmentations for the 1506 MAMA-MIA cases. Preprocessing included cropping to VOI and resampling to 1x1x1 mm\u00b3 isotropic pixel spacing."
                },
                {
                  "id": "step_5_quality_control",
                  "name": "Visual Quality Control of Automatic Segmentations",
                  "description": "Two expert breast radiologists visually inspected the preliminary automatic segmentations on 2D slices (axial, sagittal, coronal) from the first post-contrast image and categorized them as Good, Acceptable, Poor, or Missed. This step was blinded to the experts performing corrections."
                },
                {
                  "id": "step_6_expert_correction",
                  "name": "Expert Manual Correction",
                  "description": "16 experts manually corrected, inspected, and verified the preliminary automatic segmentations for 1095 missing cases (plus 411 existing expert segmentations were also reviewed). Experts segmented the primary tumor in the first post-contrast phase using the Mango viewer tool, following specific guidelines (e.g., segmenting only the primary lesion, excluding lymph nodes)."
                }
              ]
            }
          ]
        }
      ],
      "identified_tools": [
        {
          "name": "nnU-Net",
          "description": "A standard state-of-the-art deep learning model used to produce preliminary segmentations and for which pre-trained weights were shared.",
          "type": "Segmentation Framework"
        },
        {
          "name": "Mango viewer",
          "description": "The tool selected for experts to correct the automatic segmentations.",
          "type": "Annotation/Visualization Software"
        },
        {
          "name": "pycad",
          "description": "Python library used to transform original DICOM images from TCIA to NIfTI format.",
          "type": "Data Conversion Tool"
        },
        {
          "name": "seg-metrics 1.2.7",
          "description": "Python library used to compute metrics like Dice coefficient and 95% Hausdorff Distance.",
          "type": "Metrics Calculation Tool"
        },
        {
          "name": "matplotlib",
          "description": "Used for plotting MRI images in Jupyter notebooks.",
          "type": "Visualization Library"
        },
        {
          "name": "pandas",
          "description": "Used for filtering and visualizing clinical and imaging data.",
          "type": "Data Manipulation Library"
        }
      ],
      "identified_models": [
        {
          "name": "Baseline nnU-Net Model (Pre-trained Weights)",
          "description": "A vanilla nnU-Net model trained on the 1506 expert segmentations of primary tumors for transfer learning and benchmarking.",
          "type": "Segmentation Model"
        },
        {
          "name": "Preliminary Segmentation Model",
          "description": "Model trained on 331 segmentations (DUKE and TCGA-BRCA) used to generate initial segmentations for expert correction.",
          "type": "Segmentation Model"
        }
      ],
      "identified_measurements": [
        {
          "name": "Expert Primary Tumor Segmentations",
          "description": "1506 expert-corrected 3D segmentations of the primary lesion in pre-treatment DCE-MRI (first post-contrast phase).",
          "type": "Segmentation Mask"
        },
        {
          "name": "Preliminary Automatic Segmentations",
          "description": "Initial segmentations generated by the nnU-Net model before expert correction.",
          "type": "Segmentation Mask"
        },
        {
          "name": "Expert Quality Scores",
          "description": "Categorical quality assessment (Good, Acceptable, Poor, Missed) assigned by two expert radiologists to the preliminary automatic segmentations.",
          "type": "Quality Metric"
        },
        {
          "name": "Dice Similarity Coefficient (DSC)",
          "description": "Calculated between automatic and expert segmentations.",
          "type": "Segmentation Similarity Metric"
        },
        {
          "name": "95 percentile Hausdorff Distance (HD)",
          "description": "Calculated between automatic and expert segmentations.",
          "type": "Segmentation Boundary Metric"
        },
        {
          "name": "Functional Tumor Volume (FTV)",
          "description": "Volume derived from SER and PE images, used as an approximate VOI/segmentation for comparison against expert segmentation.",
          "type": "Volumetric Measurement"
        },
        {
          "name": "Harmonized Clinical and Demographic Variables",
          "description": "21 clinical, 6 demographic, and 22 imaging parameters for all 1506 cases.",
          "type": "Metadata"
        }
      ],
      "confidence_scores": {
        "Data_Collection": "High",
        "Harmonization": "High",
        "Segmentation_Quality_Control": "High (Validated by Cohen's Kappa analysis)",
        "Expert_Correction_Consistency": "Moderate (Cohen's Kappa 0.39 for 4 categories, improved to 0.53 for binary)"
      }
    }
  },
  "MODEL:gemini-3-flash-preview|SYS:87daa587a842e5258cb400e69233560a|TXT:3a994373f566fac590c6844fd21765d5|FILE_HASH:50b22a5f6906ad27d562bbaff7642c00": {
    "investigation": {
      "id": "inv_1",
      "title": "A large-scale multicenter breast cancer DCE-MRI benchmark dataset with expert segmentations",
      "description": "This study presents the MAMA-MIA dataset, a multicenter collection of 1506 pre-treatment T1-weighted dynamic contrast-enhanced MRI (DCE-MRI) cases. The dataset integrates data from four TCIA collections (DUKE, ISPY1, ISPY2, NACT) and provides expert-corrected segmentations of primary tumors and non-mass-enhanced regions, along with 49 harmonized clinical and demographic variables.",
      "studies": [
        {
          "id": "study_1",
          "title": "MAMA-MIA Dataset Development and Validation",
          "assays": [
            {
              "id": "assay_1",
              "name": "Breast Cancer Tumor Segmentation Workflow",
              "measurement_type": "Tumor Segmentation",
              "technology_type": "Magnetic Resonance Imaging (MRI)",
              "steps": [
                {
                  "id": "step_1",
                  "name": "Data Collection",
                  "description": "Sourcing 1506 pre-treatment T1-weighted DCE-MRI cases from four public collections in The Cancer Imaging Archive (TCIA): DUKE, ISPY1, ISPY2, and NACT."
                },
                {
                  "id": "step_2",
                  "name": "Data Harmonization",
                  "description": "Consolidation of 21 clinical variables, 6 demographic variables, and 22 imaging parameters into a standardized format; reorientation of axial MRIs to LAS and sagittal MRIs to PSR coordinate systems."
                },
                {
                  "id": "step_3",
                  "name": "Preliminary Automatic Segmentation",
                  "description": "Generation of initial tumor masks using an nnU-Net model trained on 331 expert-validated cases from DUKE and TCGA-BRCA."
                },
                {
                  "id": "step_4",
                  "name": "Visual Quality Control",
                  "description": "Two expert radiologists visually assessed all preliminary automatic segmentations, categorizing them as Good, Acceptable, Poor, or Missed."
                },
                {
                  "id": "step_5",
                  "name": "Expert Manual Correction",
                  "description": "16 breast cancer experts manually corrected and verified all 1506 segmentations using the Mango viewer, following specific guidelines for primary tumor delineation."
                },
                {
                  "id": "step_6",
                  "name": "Dataset Standardization",
                  "description": "Standardization of folder structure and file naming (NIfTI format) to support plug-and-play AI training and easy retrieval."
                },
                {
                  "id": "step_7",
                  "name": "Baseline Model Training",
                  "description": "Training a vanilla nnU-Net tumor segmentation model on the final 1506 expert-corrected segmentations over 1000 epochs."
                }
              ]
            }
          ]
        }
      ]
    },
    "identified_tools": [
      "The Cancer Imaging Archive (TCIA)",
      "nnU-Net",
      "nibabel",
      "SimpleITK",
      "Mango viewer",
      "pycad",
      "seg-metrics"
    ],
    "identified_models": [
      "nnU-Net segmentation model",
      "MedSAM",
      "SAM"
    ],
    "identified_measurements": [
      "T1-weighted dynamic contrast-enhanced MRI (DCE-MRI)",
      "Dice Similarity Coefficient (DSC)",
      "95% Hausdorff Distance (HD)",
      "Functional Tumor Volume (FTV)",
      "Pathological Complete Response (pCR)"
    ],
    "confidence_scores": {
      "investigation_extraction": 0.99,
      "hierarchy_reconstruction": 0.98,
      "workflow_steps_accuracy": 0.97,
      "tool_identification": 0.95
    }
  },
  "MODEL:gemini-robotics-er-1.5-preview|SYS:87daa587a842e5258cb400e69233560a|TXT:3a994373f566fac590c6844fd21765d5|FILE_HASH:50b22a5f6906ad27d562bbaff7642c00": {
    "investigation": {
      "id": "inv_1",
      "title": "A large-scale multicenter breast cancer DCE-MRI benchmark dataset with expert segmentations",
      "description": "This study presents a multicenter dataset of 1506 pre-treatment T1-weighted dynamic contrast-enhanced MRI cases for breast cancer research. The dataset includes expert annotations of primary tumors and non-mass-enhanced regions. To create this resource, imaging data from four collections in The Cancer Imaging Archive (TCIA) were integrated. A deep learning model was trained to generate preliminary segmentations, which were subsequently corrected and verified by 16 breast cancer experts. The dataset also includes 49 harmonized clinical and demographic variables, as well as pre-trained weights for a baseline nnU-Net model. This resource addresses a critical gap in publicly available breast cancer datasets, enabling the development, validation, and benchmarking of advanced deep learning models for breast cancer diagnostics, treatment response prediction, and personalized care.",
      "studies": [
        {
          "id": "study_1",
          "title": "MAMA-MIA Dataset Creation and Annotation Workflow",
          "assays": [
            {
              "id": "assay_1",
              "name": "DCE-MRI Data Collection, Harmonization, and Segmentation",
              "measurement_type": "DCE-MRI",
              "technology_type": "Magnetic Resonance Imaging",
              "steps": [
                {
                  "id": "step_1",
                  "name": "Data Collection from Public Repositories",
                  "description": "DCE-MRI cases were collected from four public collections available on TCIA: I-SPY1/ACRIN 6657 trial (ISPY1), I-SPY2/ACRIN 6698 trial (ISPY2), NACT-Pilot (NACT), and Duke-Breast-Cancer-MRI (DUKE). A total of 1506 cases were initially sourced."
                },
                {
                  "id": "step_2",
                  "name": "Case Selection based on Clinical Criteria",
                  "description": "Cases were filtered based on specific criteria: 1) pre-treatment DCE-MRI acquired at diagnosis before Neoadjuvant Chemotherapy (NAC) started, 2) availability of clinical data including Pathologic Complete Response (pCR) to NAC or five-year survival information, and 3) quality control by experts to exclude cases without sufficient contrast enhancement or with artifacts impeding accurate segmentation."
                },
                {
                  "id": "step_3",
                  "name": "Data Harmonization and Standardization",
                  "description": "Clinical and imaging data from the selected cases were consolidated and harmonized into a single table. This included standardizing 21 clinical variables, 6 demographic variables, and 22 imaging parameters. The dataset folder structure was standardized for easy retrieval, and image orientation was standardized to LAS (left-anterior-superior) for axial MRIs and PSR (posterior-superior-right) for sagittal MRIs."
                },
                {
                  "id": "step_4",
                  "name": "Preliminary Automatic Segmentation Generation",
                  "description": "A standard state-of-the-art deep learning model (nnU-Net) was trained using private expert segmentations from DUKE and TCGA-BRCA collections (331 cases total). This model was used to generate preliminary automatic segmentations for all 1506 cases in the MAMA-MIA dataset."
                },
                {
                  "id": "step_5",
                  "name": "Visual Quality Control of Preliminary Segmentations",
                  "description": "Two expert breast radiologists visually assessed the quality of the preliminary automatic segmentations using an in-house graphical user interface (GUI). Segmentations were categorized into four quality categories: Good, Acceptable, Poor, or Missed. This assessment was used to stratify cases for manual correction and to develop quality control mechanisms."
                },
                {
                  "id": "step_6",
                  "name": "Expert Manual Correction of Segmentations",
                  "description": "Sixteen breast cancer experts (radiologists, surgical oncologist, medical physicist) manually corrected the preliminary automatic segmentations for the 1095 cases that lacked initial expert segmentations. The corrections were performed on the first post-contrast phase using the Mango viewer tool, following specific guidelines to segment only the primary tumor and exclude healthy tissue or artifacts."
                },
                {
                  "id": "step_7",
                  "name": "Final Dataset Assembly and Model Training",
                  "description": "The final MAMA-MIA dataset was assembled, including the harmonized clinical and imaging data, train/test splits, preliminary automatic segmentation quality scores, images, and expert-corrected segmentations. Pre-trained weights for a baseline nnU-Net model, trained on the 1506 expert segmentations, were also provided as an additional contribution."
                }
              ]
            }
          ]
        }
      ]
    },
    "identified_tools": [
      {
        "name": "nnU-Net",
        "description": "Deep learning framework used to generate preliminary automatic segmentations and train the baseline segmentation model."
      },
      {
        "name": "Mango viewer",
        "description": "Tool used by experts for manual correction of automatic segmentations."
      },
      {
        "name": "TCIA (The Cancer Imaging Archive)",
        "description": "Public repository where the source DCE-MRI collections (ISPY1, ISPY2, DUKE, NACT) are available."
      },
      {
        "name": "Jupyter notebooks",
        "description": "Provided scripts for data filtering, visualization, and preprocessing."
      },
      {
        "name": "pandas library",
        "description": "Python library used for filtering and visualizing clinical and imaging data."
      },
      {
        "name": "matplotlib library",
        "description": "Python library used for plotting MRI images and segmentation contours."
      },
      {
        "name": "pycad Python library",
        "description": "Python library used to transform original DICOM images from TCIA to NIfTI format."
      },
      {
        "name": "seg-metrics Python library",
        "description": "Python library used to compute metrics such as Dice coefficient and 95% Hausdorff Distance."
      }
    ],
    "identified_models": [
      {
        "name": "nnU-Net segmentation model",
        "description": "A baseline tumor segmentation model trained on the 1506 expert segmentations of the MAMA-MIA dataset, with pre-trained weights provided as part of the resource."
      }
    ],
    "identified_measurements": [
      {
        "name": "DCE-MRI",
        "description": "Dynamic Contrast-Enhanced Magnetic Resonance Imaging scans of breast cancer patients."
      },
      {
        "name": "Expert Segmentation",
        "description": "Manual annotations of primary tumors and non-mass-enhanced regions performed by breast cancer experts."
      },
      {
        "name": "Automatic Segmentation",
        "description": "Preliminary segmentations generated by the nnU-Net deep learning model."
      },
      {
        "name": "Clinical Variables",
        "description": "Data including pathological complete response (pCR) to NAC, survival status, tumor subtype, and other patient characteristics."
      },
      {
        "name": "Demographic Variables",
        "description": "Patient information such as age and ethnicity."
      },
      {
        "name": "Imaging Parameters",
        "description": "Acquisition details including magnetic field strength, acquisition plane, scanner manufacturer, slice thickness, and pixel spacing."
      },
      {
        "name": "Dice Similarity Coefficient (DSC)",
        "description": "Metric used to quantify agreement between automatic and expert segmentations."
      },
      {
        "name": "Hausdorff Distance (HD)",
        "description": "Metric used to quantify alignment between automatic and expert segmentations."
      }
    ],
    "confidence_scores": {
      "investigation": 5,
      "studies": 5,
      "assays": 5,
      "steps": 5,
      "identified_tools": 5,
      "identified_models": 5,
      "identified_measurements": 5
    }
  }
}